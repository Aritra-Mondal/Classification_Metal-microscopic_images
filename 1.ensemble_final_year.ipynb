{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ensemble_final_year.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deoE6t0x2cfL",
        "outputId": "00864711-968f-473e-b977-88c7dcfe61bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms, models\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(torch.cuda.is_available())\n",
        "#pretrained=True will download a pretrained network for us\n",
        "\n",
        "\n",
        "\n",
        "#Freezing model parameters and defining the fully connected network to be attached to the model, loss function and the optimizer.\n",
        "\n",
        "\n",
        "\n",
        "# for param in model1.parameters():\n",
        "#     param.requires_grad = False\n",
        "# for param in model2.parameters():\n",
        "#     param.requires_grad = False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# c=0\n",
        "# for param in model.parameters():\n",
        "#   if (param.requires_grad):\n",
        "#     c+=1  \n",
        "# print(c)\n",
        "\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "# optimizer = torch.optim.Adam(model.classifier.parameters(), lr=0.003,)\n",
        "# model.to(device)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = models.alexnet(pretrained=True)\n",
        "# model\n",
        "\n",
        "# for param in model.parameters():\n",
        "#     param.requires_grad = True\n"
      ],
      "metadata": {
        "id": "y9gOVCgv2seL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fc = nn.Sequential(\n",
        "#     nn.Linear(9216, 4096),\n",
        "#     nn.ReLU(),\n",
        "#     nn.Dropout(0.4),\n",
        "#     nn.Linear(4096,5),\n",
        "    \n",
        "# )\n",
        "# model.classifier = fc"
      ],
      "metadata": {
        "id": "mpmFQKz_2zr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "model\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "id": "dVo4VreQxLha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fc = nn.Sequential(\n",
        "    nn.Linear(512, 320),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.4),\n",
        "    nn.Linear(320,5)\n",
        ")\n",
        "model.fc = fc"
      ],
      "metadata": {
        "id": "cuUHi4ZSxMcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.0001,)\n",
        "model\n",
        "model_save_name1 = \"resnet_5class.pth\"\n"
      ],
      "metadata": {
        "id": "wp0WJSwb26Vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your transforms for the training, validation, and testing sets\n",
        "train_transforms = transforms.Compose([transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
        "                                      transforms.RandomRotation(degrees=15),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.CenterCrop(size=224),  # Image net standards\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                           [0.229, 0.224, 0.225])\n",
        "                                      ])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                                                           [0.229, 0.224, 0.225])])\n",
        "\n",
        "validation_transforms = transforms.Compose([transforms.Resize(224),\n",
        "                                            transforms.CenterCrop(224),\n",
        "                                            transforms.ToTensor(),\n",
        "                                            transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                                                                 [0.229, 0.224, 0.225])])\n",
        "train_dir='/content/drive/My Drive/dataset8/train'\n",
        "test_dir='/content/drive/My Drive/dataset8/test'\n",
        "batch_size=16\n",
        "#Loading in the dataset\n",
        "\n",
        "train_data = datasets.ImageFolder(train_dir,transform=train_transforms)\n",
        "test_data = datasets.ImageFolder(test_dir,transform=test_transforms)\n",
        "\n",
        "print(train_data.class_to_idx)\n",
        "# number of subprocesses to use for data loading\n",
        "num_workers = 0\n",
        "# percentage of training set to use as validation\n",
        "valid_size = 0.2\n",
        "\n",
        "test_size = 0.0\n",
        "\n",
        "# obtain training indices that will be used for validation\n",
        "num_train = len(train_data)\n",
        "indices = list(range(num_train))\n",
        "test_indices=list(range(len(test_data)))\n",
        "# print(indices)\n",
        "np.random.shuffle(indices)\n",
        "# print(indices)\n",
        "valid_split = int(np.floor((valid_size) * num_train))\n",
        "test_split = int(np.floor((valid_size+test_size) * num_train))\n",
        "valid_idx, test_idx, train_idx = indices[:valid_split], indices[valid_split:test_split], indices[test_split:]\n",
        "print(len(valid_idx), len(test_indices), len(train_idx))\n",
        "\n",
        "# train_idx= [328, 125, 429, 789, 305, 773, 580, 787, 170, 86, 639, 837, 553, 856, 732, 192, 103, 204, 659, 157, 778, 551, 761, 524, 205, 309, 48, 567, 702, 293, 533, 198, 131, 544, 464, 166, 785, 803, 113, 835, 780, 729, 797, 80, 655, 676, 566, 462, 169, 211, 449, 348, 738, 848, 535, 623, 494, 814, 790, 41, 838, 606, 486, 519, 827, 460, 723, 647, 667, 463, 446, 187, 608, 719, 311, 152, 578, 531, 443, 695, 767, 425, 569, 441, 691, 678, 800, 721, 282, 323, 706, 391, 330, 213, 561, 257, 3, 456, 665, 868, 532, 407, 350, 31, 251, 371, 189, 740, 461, 585, 396, 866, 308, 850, 862, 668, 93, 165, 488, 160, 320, 607, 417, 235, 314, 366, 836, 164, 627, 351, 852, 841, 354, 818, 594, 252, 118, 859, 53, 17, 798, 440, 209, 231, 404, 699, 66, 847, 179, 515, 753, 822, 241, 514, 629, 133, 562, 660, 801, 742, 230, 398, 362, 298, 194, 755, 733, 278, 421, 650, 586, 413, 831, 579, 556, 316, 709, 42, 222, 206, 447, 536, 741, 574, 52, 468, 474, 700, 769, 872, 200, 869, 402, 4, 786, 851, 258, 201, 11, 573, 839, 557, 24, 269, 642, 303, 199, 182, 518, 791, 508, 480, 95, 746, 656, 89, 126, 319, 409, 161, 559, 146, 246, 530, 467, 156, 871, 295, 582, 106, 344, 679, 121, 360, 207, 622, 715, 281, 324, 403, 26, 534, 457, 444, 130, 405, 490, 527, 365, 459, 497, 758, 683, 8, 718, 274, 772, 181, 339, 292, 430, 347, 50, 528, 618, 673, 380, 855, 630, 342, 570, 345, 750, 603, 598, 560, 223, 604, 771, 184, 82, 710, 543, 406, 326, 619, 147, 220, 420, 437, 123, 180, 765, 806, 688, 505, 431, 434, 110, 249, 112, 766, 433, 191, 343, 385, 44, 783, 511, 484, 492, 285, 27, 829, 117, 808, 418, 693, 6, 224, 384, 286, 45, 552, 94, 392, 538, 815, 128, 752, 712, 275, 428, 526, 751, 558, 15, 664, 690, 466, 136, 172, 236, 410, 845, 242, 730, 624, 768, 135, 111, 596, 600, 361, 811, 842, 237, 18, 73, 400, 49, 628, 134, 364, 493, 250, 663, 280, 572, 465, 633, 356, 713, 754, 138, 64, 304, 482, 74, 63, 632, 225, 19, 196, 254, 563, 154, 141, 260, 675, 423, 399, 419, 735, 823, 183, 383, 775, 263, 734, 92, 472, 863, 819, 694, 478, 759, 813, 546, 707, 377, 81, 641, 809, 129, 475, 101, 338, 186, 571, 625, 357, 333, 416, 817, 318, 334, 288, 158, 233, 7, 336, 47, 253, 564, 833, 542, 781, 353, 714, 14, 238, 327, 9, 674, 479, 506, 645, 682, 358, 671, 491, 744, 686, 692, 91, 636, 210, 13, 680, 454, 816, 701, 115, 270, 705, 577, 259, 610, 188, 438, 565, 75, 451, 168, 748, 60, 171, 537, 346, 550, 397, 197, 747, 621, 105, 843, 849, 234, 23, 620, 62, 592, 1, 784, 379, 760, 684, 276, 145, 626, 762, 148, 796, 584, 485, 368, 72, 602, 401, 39, 372, 513, 337, 613, 589, 581, 614, 312, 177, 239, 291, 788, 163, 57, 387, 521, 382, 363, 203, 436, 218, 262, 512, 587, 393, 272, 107, 388, 109, 476, 143, 777, 16, 448, 84, 638, 412, 261, 805, 687, 67, 321, 697, 2, 378, 331, 247, 763, 826, 119, 352, 510, 799, 708, 240, 496, 432, 522, 245, 840, 646, 70, 176, 605, 367, 793, 870, 540, 634, 208, 0, 481, 507, 83, 87, 38, 373, 662, 390, 25, 568, 764, 774, 689, 770, 10, 539, 296, 717, 864, 140, 725, 35, 435, 68, 369, 502, 243, 834, 685, 661, 640, 310, 549, 471, 265, 185, 737, 698, 643, 394, 867, 832, 792, 414, 56, 307, 283, 341, 266, 844, 469, 202, 214, 37, 520, 450, 498, 375, 652, 151, 575, 150, 175, 142, 601, 517, 854, 424, 116, 174, 12, 612, 853, 100, 422, 576, 727, 137, 22, 21, 36, 69, 193, 860, 325, 124, 670, 32, 277, 669, 217, 120, 597, 648, 500, 637, 359, 427, 489, 745, 178, 370, 299, 726, 297, 541, 34, 711, 470, 232, 828, 55, 219, 5, 139, 794, 76]\n",
        "# valid_idx= [616, 523, 455, 649, 226, 329, 99, 504, 96, 821, 374, 102, 590, 595, 159, 609, 88, 122, 273, 666, 599, 820, 807, 509, 408, 483, 846, 548, 477, 289, 611, 452, 313, 144, 97, 722, 782, 153, 306, 216, 65, 90, 268, 861, 439, 317, 635, 381, 79, 657, 29, 716, 300, 651, 728, 654, 583, 724, 588, 525, 195, 395, 335, 858, 46, 453, 739, 749, 61, 812, 810, 315, 865, 681, 271, 547, 43, 458, 615, 415, 132, 617, 114, 555, 376, 302, 644, 51, 264, 757, 284, 279, 255, 332, 248, 487, 672, 162, 149, 677, 442, 155, 857, 386, 503, 631, 411, 212, 173, 825, 499, 33, 529, 98, 703, 104, 77, 830, 167, 593, 244, 743, 294, 190, 71, 340, 389, 736, 227, 58, 731, 78, 495, 473, 40, 108, 658, 776, 322, 591, 30, 795, 228, 802, 290, 256, 804, 696, 59, 704, 85, 349, 445, 54, 720, 127, 215, 229, 221, 516, 28, 426, 20, 824, 501, 779, 554, 287, 756, 301, 355, 653, 267, 545]\n",
        "\n",
        "# define samplers for obtaining training and validation batches\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "test_sampler = SubsetRandomSampler(test_indices)\n",
        "\n",
        "# prepare data loaders (combine dataset and sampler)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "    sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
        "    sampler=valid_sampler, num_workers=num_workers)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
        "    sampler=test_sampler, num_workers=num_workers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5aLSy823AJA",
        "outputId": "3151a165-f448-4d12-82a4-c69935d3072f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'martensite': 0, 'network': 1, 'pearlite': 2, 'spheroidite': 3, 'spheroidite_widmanstatten': 4}\n",
            "174 221 699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the model and saving checkpoints of best performances. That is lower validation loss and higher accuracy\n",
        "epochs = 50\n",
        "\n",
        "\n",
        "valid_loss_min = np.Inf \n",
        "train_loss_list=[]\n",
        "valid_loss_list=[]\n",
        "valid_accuracy_list=[]\n",
        "train_accuracy_list=[]\n",
        "import time \n",
        "\n",
        "for epoch in range(epochs):\n",
        "    \n",
        "    start = time.time()\n",
        "    \n",
        "    # scheduler.step()\n",
        "    model.train()\n",
        "    \n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    train_loss = 0.0\n",
        "    train_acc=0.0\n",
        "    \n",
        "    for inputs, labels in train_loader:\n",
        "        \n",
        "       \n",
        "        # Move input and label tensors to the default device\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        logps = model(inputs)\n",
        "        loss = criterion(logps, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        \n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        t_accuracy = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            \n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            logps = model.forward(inputs)\n",
        "            batch_loss = criterion(logps, labels)\n",
        "\n",
        "            valid_loss += batch_loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            ps = torch.exp(logps)\n",
        "            top_p, top_class = ps.topk(1, dim=1)\n",
        "            equals = top_class == labels.view(*top_class.shape)\n",
        "            t_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "                       \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        accuracy = 0\n",
        "        for inputs, labels in valid_loader:\n",
        "            \n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            logps = model.forward(inputs)\n",
        "            batch_loss = criterion(logps, labels)\n",
        "\n",
        "            valid_loss += batch_loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            ps = torch.exp(logps)\n",
        "            top_p, top_class = ps.topk(1, dim=1)\n",
        "            equals = top_class == labels.view(*top_class.shape)\n",
        "            accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "                    \n",
        "            \n",
        "            \n",
        "# calculate average losses\n",
        "    train_loss = train_loss/len(train_loader)\n",
        "    valid_loss = valid_loss/len(valid_loader)\n",
        "    valid_accuracy = accuracy/len(valid_loader)\n",
        "    train_accuracy = t_accuracy/len(train_loader)\n",
        "\n",
        "    \n",
        "    # scheduler.step()\n",
        "\n",
        "    train_loss_list.append(train_loss)\n",
        "    valid_loss_list.append(valid_loss)\n",
        "    train_accuracy_list.append(train_accuracy)\n",
        "    valid_accuracy_list.append(valid_accuracy) \n",
        "      \n",
        "    # print training/validation statistics \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}  \\tValidation Accuracy: {:.6f}'.format(epoch + 1, train_loss, valid_loss,valid_accuracy))\n",
        "            \n",
        "    \n",
        "    \n",
        "    if valid_loss <= valid_loss_min:\n",
        "      \n",
        "      \n",
        "      print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "      valid_loss_min,\n",
        "      valid_loss))\n",
        "      \n",
        "      path = F\"/content/drive/My Drive/{model_save_name1}\" \n",
        "\n",
        "      torch.save(model.state_dict(), path)\n",
        "      valid_loss_min = valid_loss        \n",
        "       \n",
        "    print(f\"Time per epoch: {(time.time() - start):.3f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxw10-DK3Cp9",
        "outputId": "51417c03-7fcc-4bb4-a402-9b6822705a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \tTraining Loss: 1.472053 \tValidation Loss: 6.557750  \tValidation Accuracy: 0.556818\n",
            "Validation loss decreased (inf --> 6.557750).  Saving model ...\n",
            "Time per epoch: 32.884 seconds\n",
            "Epoch: 2 \tTraining Loss: 1.201001 \tValidation Loss: 5.076664  \tValidation Accuracy: 0.737013\n",
            "Validation loss decreased (6.557750 --> 5.076664).  Saving model ...\n",
            "Time per epoch: 27.629 seconds\n",
            "Epoch: 3 \tTraining Loss: 1.013792 \tValidation Loss: 4.071131  \tValidation Accuracy: 0.826299\n",
            "Validation loss decreased (5.076664 --> 4.071131).  Saving model ...\n",
            "Time per epoch: 29.500 seconds\n",
            "Epoch: 4 \tTraining Loss: 0.863225 \tValidation Loss: 3.406502  \tValidation Accuracy: 0.844156\n",
            "Validation loss decreased (4.071131 --> 3.406502).  Saving model ...\n",
            "Time per epoch: 27.462 seconds\n",
            "Epoch: 5 \tTraining Loss: 0.770982 \tValidation Loss: 2.945157  \tValidation Accuracy: 0.844968\n",
            "Validation loss decreased (3.406502 --> 2.945157).  Saving model ...\n",
            "Time per epoch: 27.565 seconds\n",
            "Epoch: 6 \tTraining Loss: 0.686542 \tValidation Loss: 2.666169  \tValidation Accuracy: 0.840097\n",
            "Validation loss decreased (2.945157 --> 2.666169).  Saving model ...\n",
            "Time per epoch: 27.411 seconds\n",
            "Epoch: 7 \tTraining Loss: 0.629250 \tValidation Loss: 2.507730  \tValidation Accuracy: 0.861201\n",
            "Validation loss decreased (2.666169 --> 2.507730).  Saving model ...\n",
            "Time per epoch: 27.527 seconds\n",
            "Epoch: 8 \tTraining Loss: 0.581789 \tValidation Loss: 2.194652  \tValidation Accuracy: 0.883117\n",
            "Validation loss decreased (2.507730 --> 2.194652).  Saving model ...\n",
            "Time per epoch: 27.500 seconds\n",
            "Epoch: 9 \tTraining Loss: 0.560618 \tValidation Loss: 2.067883  \tValidation Accuracy: 0.886364\n",
            "Validation loss decreased (2.194652 --> 2.067883).  Saving model ...\n",
            "Time per epoch: 27.544 seconds\n",
            "Epoch: 10 \tTraining Loss: 0.521046 \tValidation Loss: 1.965341  \tValidation Accuracy: 0.884740\n",
            "Validation loss decreased (2.067883 --> 1.965341).  Saving model ...\n",
            "Time per epoch: 27.732 seconds\n",
            "Epoch: 11 \tTraining Loss: 0.533024 \tValidation Loss: 1.845990  \tValidation Accuracy: 0.897727\n",
            "Validation loss decreased (1.965341 --> 1.845990).  Saving model ...\n",
            "Time per epoch: 27.884 seconds\n",
            "Epoch: 12 \tTraining Loss: 0.506976 \tValidation Loss: 1.701087  \tValidation Accuracy: 0.873377\n",
            "Validation loss decreased (1.845990 --> 1.701087).  Saving model ...\n",
            "Time per epoch: 27.478 seconds\n",
            "Epoch: 13 \tTraining Loss: 0.489219 \tValidation Loss: 1.701005  \tValidation Accuracy: 0.913149\n",
            "Validation loss decreased (1.701087 --> 1.701005).  Saving model ...\n",
            "Time per epoch: 27.590 seconds\n",
            "Epoch: 14 \tTraining Loss: 0.485936 \tValidation Loss: 1.680411  \tValidation Accuracy: 0.890422\n",
            "Validation loss decreased (1.701005 --> 1.680411).  Saving model ...\n",
            "Time per epoch: 27.466 seconds\n",
            "Epoch: 15 \tTraining Loss: 0.446653 \tValidation Loss: 1.574087  \tValidation Accuracy: 0.872565\n",
            "Validation loss decreased (1.680411 --> 1.574087).  Saving model ...\n",
            "Time per epoch: 27.608 seconds\n",
            "Epoch: 16 \tTraining Loss: 0.410601 \tValidation Loss: 1.551527  \tValidation Accuracy: 0.909091\n",
            "Validation loss decreased (1.574087 --> 1.551527).  Saving model ...\n",
            "Time per epoch: 27.513 seconds\n",
            "Epoch: 17 \tTraining Loss: 0.385521 \tValidation Loss: 1.449742  \tValidation Accuracy: 0.879870\n",
            "Validation loss decreased (1.551527 --> 1.449742).  Saving model ...\n",
            "Time per epoch: 27.410 seconds\n",
            "Epoch: 18 \tTraining Loss: 0.414156 \tValidation Loss: 1.338782  \tValidation Accuracy: 0.914773\n",
            "Validation loss decreased (1.449742 --> 1.338782).  Saving model ...\n",
            "Time per epoch: 27.421 seconds\n",
            "Epoch: 19 \tTraining Loss: 0.446889 \tValidation Loss: 1.321985  \tValidation Accuracy: 0.885552\n",
            "Validation loss decreased (1.338782 --> 1.321985).  Saving model ...\n",
            "Time per epoch: 27.442 seconds\n",
            "Epoch: 20 \tTraining Loss: 0.374917 \tValidation Loss: 1.350314  \tValidation Accuracy: 0.891234\n",
            "Time per epoch: 27.291 seconds\n",
            "Epoch: 21 \tTraining Loss: 0.411032 \tValidation Loss: 1.305648  \tValidation Accuracy: 0.902597\n",
            "Validation loss decreased (1.321985 --> 1.305648).  Saving model ...\n",
            "Time per epoch: 27.279 seconds\n",
            "Epoch: 22 \tTraining Loss: 0.372180 \tValidation Loss: 1.268367  \tValidation Accuracy: 0.936688\n",
            "Validation loss decreased (1.305648 --> 1.268367).  Saving model ...\n",
            "Time per epoch: 28.099 seconds\n",
            "Epoch: 23 \tTraining Loss: 0.357957 \tValidation Loss: 1.292809  \tValidation Accuracy: 0.907468\n",
            "Time per epoch: 27.303 seconds\n",
            "Epoch: 24 \tTraining Loss: 0.379556 \tValidation Loss: 1.258373  \tValidation Accuracy: 0.886364\n",
            "Validation loss decreased (1.268367 --> 1.258373).  Saving model ...\n",
            "Time per epoch: 29.263 seconds\n",
            "Epoch: 25 \tTraining Loss: 0.341507 \tValidation Loss: 1.199774  \tValidation Accuracy: 0.913961\n",
            "Validation loss decreased (1.258373 --> 1.199774).  Saving model ...\n",
            "Time per epoch: 27.480 seconds\n",
            "Epoch: 26 \tTraining Loss: 0.349723 \tValidation Loss: 1.159694  \tValidation Accuracy: 0.903409\n",
            "Validation loss decreased (1.199774 --> 1.159694).  Saving model ...\n",
            "Time per epoch: 27.847 seconds\n",
            "Epoch: 27 \tTraining Loss: 0.323101 \tValidation Loss: 1.115228  \tValidation Accuracy: 0.914773\n",
            "Validation loss decreased (1.159694 --> 1.115228).  Saving model ...\n",
            "Time per epoch: 27.389 seconds\n",
            "Epoch: 28 \tTraining Loss: 0.344028 \tValidation Loss: 1.120280  \tValidation Accuracy: 0.920455\n",
            "Time per epoch: 27.361 seconds\n",
            "Epoch: 29 \tTraining Loss: 0.310944 \tValidation Loss: 1.011425  \tValidation Accuracy: 0.919643\n",
            "Validation loss decreased (1.115228 --> 1.011425).  Saving model ...\n",
            "Time per epoch: 27.295 seconds\n",
            "Epoch: 30 \tTraining Loss: 0.331747 \tValidation Loss: 1.010743  \tValidation Accuracy: 0.906656\n",
            "Validation loss decreased (1.011425 --> 1.010743).  Saving model ...\n",
            "Time per epoch: 27.417 seconds\n",
            "Epoch: 31 \tTraining Loss: 0.311225 \tValidation Loss: 1.050334  \tValidation Accuracy: 0.919643\n",
            "Time per epoch: 27.253 seconds\n",
            "Epoch: 32 \tTraining Loss: 0.301567 \tValidation Loss: 0.983675  \tValidation Accuracy: 0.908279\n",
            "Validation loss decreased (1.010743 --> 0.983675).  Saving model ...\n",
            "Time per epoch: 27.152 seconds\n",
            "Epoch: 33 \tTraining Loss: 0.318584 \tValidation Loss: 0.963307  \tValidation Accuracy: 0.902597\n",
            "Validation loss decreased (0.983675 --> 0.963307).  Saving model ...\n",
            "Time per epoch: 27.978 seconds\n",
            "Epoch: 34 \tTraining Loss: 0.298516 \tValidation Loss: 1.058452  \tValidation Accuracy: 0.931818\n",
            "Time per epoch: 27.308 seconds\n",
            "Epoch: 35 \tTraining Loss: 0.289609 \tValidation Loss: 0.958866  \tValidation Accuracy: 0.908279\n",
            "Validation loss decreased (0.963307 --> 0.958866).  Saving model ...\n",
            "Time per epoch: 27.252 seconds\n",
            "Epoch: 36 \tTraining Loss: 0.302394 \tValidation Loss: 0.986846  \tValidation Accuracy: 0.913149\n",
            "Time per epoch: 27.204 seconds\n",
            "Epoch: 37 \tTraining Loss: 0.298957 \tValidation Loss: 0.942595  \tValidation Accuracy: 0.918831\n",
            "Validation loss decreased (0.958866 --> 0.942595).  Saving model ...\n",
            "Time per epoch: 27.345 seconds\n",
            "Epoch: 38 \tTraining Loss: 0.283042 \tValidation Loss: 0.918654  \tValidation Accuracy: 0.901786\n",
            "Validation loss decreased (0.942595 --> 0.918654).  Saving model ...\n",
            "Time per epoch: 27.334 seconds\n",
            "Epoch: 39 \tTraining Loss: 0.297442 \tValidation Loss: 0.958474  \tValidation Accuracy: 0.905844\n",
            "Time per epoch: 27.258 seconds\n",
            "Epoch: 40 \tTraining Loss: 0.269834 \tValidation Loss: 0.896508  \tValidation Accuracy: 0.925325\n",
            "Validation loss decreased (0.918654 --> 0.896508).  Saving model ...\n",
            "Time per epoch: 27.275 seconds\n",
            "Epoch: 41 \tTraining Loss: 0.329227 \tValidation Loss: 0.951698  \tValidation Accuracy: 0.907468\n",
            "Time per epoch: 27.215 seconds\n",
            "Epoch: 42 \tTraining Loss: 0.261812 \tValidation Loss: 0.864618  \tValidation Accuracy: 0.931006\n",
            "Validation loss decreased (0.896508 --> 0.864618).  Saving model ...\n",
            "Time per epoch: 27.340 seconds\n",
            "Epoch: 43 \tTraining Loss: 0.253359 \tValidation Loss: 0.846885  \tValidation Accuracy: 0.925325\n",
            "Validation loss decreased (0.864618 --> 0.846885).  Saving model ...\n",
            "Time per epoch: 27.405 seconds\n",
            "Epoch: 44 \tTraining Loss: 0.293834 \tValidation Loss: 0.866508  \tValidation Accuracy: 0.914773\n",
            "Time per epoch: 27.593 seconds\n",
            "Epoch: 45 \tTraining Loss: 0.244743 \tValidation Loss: 0.850189  \tValidation Accuracy: 0.913961\n",
            "Time per epoch: 27.247 seconds\n",
            "Epoch: 46 \tTraining Loss: 0.270752 \tValidation Loss: 0.812997  \tValidation Accuracy: 0.954545\n",
            "Validation loss decreased (0.846885 --> 0.812997).  Saving model ...\n",
            "Time per epoch: 27.337 seconds\n",
            "Epoch: 47 \tTraining Loss: 0.280803 \tValidation Loss: 0.862863  \tValidation Accuracy: 0.901786\n",
            "Time per epoch: 27.177 seconds\n",
            "Epoch: 48 \tTraining Loss: 0.267931 \tValidation Loss: 0.871072  \tValidation Accuracy: 0.913149\n",
            "Time per epoch: 27.158 seconds\n",
            "Epoch: 49 \tTraining Loss: 0.289867 \tValidation Loss: 0.821729  \tValidation Accuracy: 0.920455\n",
            "Time per epoch: 27.106 seconds\n",
            "Epoch: 50 \tTraining Loss: 0.279218 \tValidation Loss: 0.820862  \tValidation Accuracy: 0.918019\n",
            "Time per epoch: 27.087 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, criterion):\n",
        "  # monitor test loss and accuracy\n",
        "  import numpy as np\n",
        "  model.eval()\n",
        "\n",
        "  ori_idx=[]\n",
        "  nb_classes=5\n",
        "  confusion_matrix1 = torch.zeros(nb_classes, nb_classes)\n",
        "  y_ori=[]\n",
        "  y_pre=[]\n",
        "  test_loss = 0.\n",
        "  correct = 0.\n",
        "  total = 0.\n",
        "  model.eval()\n",
        "  for batch_idx, (data, target) in enumerate(test_loader):\n",
        "    # move to GPU\n",
        "    if torch.cuda.is_available():\n",
        "      data, target = data.cuda(), target.cuda()\n",
        "    # forward pass: compute predicted outputs by passing inputs to the model\n",
        "    output = model(data)\n",
        "    # print(output)\n",
        "    # p = torch.nn.functional.softmax(output, dim=1)\n",
        "    p = torch.nn.functional.softmax(output, dim=1)\n",
        "    # print(p)\n",
        "    ori_idx.append(target)\n",
        "    \n",
        "    # calculate the loss\n",
        "    loss = criterion(output, target)\n",
        "    # update average test loss \n",
        "    test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
        "    # convert output probabilities to predicted class\n",
        "    _, preds = torch.max(output, 1)\n",
        "    pred = output.data.max(1, keepdim=True)[1]\n",
        "    np_target=target.cpu().numpy()\n",
        "    np_preds=preds.cpu().numpy()\n",
        "    print(np_target)\n",
        "    print(np_preds)\n",
        "    y_ori.extend(list(np_target))\n",
        "    y_pre.extend(list(np_preds))\n",
        "    for t, p in zip(target.view(-1), preds.view(-1)):\n",
        "      confusion_matrix1[t.long(), p.long()] += 1\n",
        "    # compare predictions to true label\n",
        "    correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "    total += data.size(0)\n",
        "            \n",
        "  print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "  print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (100. * correct / total, correct, total))\n",
        "  \n",
        "  print(confusion_matrix1)\n",
        "  from sklearn.metrics import classification_report,confusion_matrix\n",
        "  print(classification_report(y_ori, y_pre, target_names=train_data.class_to_idx))\n",
        "  import seaborn as sns\n",
        "  sns.heatmap(confusion_matrix1,\n",
        "            annot=True,\n",
        "            cmap=\"Set2\")\n",
        "  # print(ori_idx)\n",
        "  print(\"actual label\",y_ori)\n",
        "  print(\"predicted label\",y_pre)\n",
        "test(model, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-ZuAo8KDldCM",
        "outputId": "442aa441-3ac2-4a0a-d5b1-ca1eff48a37e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 3 4 0 3 4 1 3 3 0 1 2 3 0 3 0]\n",
            "[0 3 4 0 3 4 1 3 3 0 1 2 3 0 0 0]\n",
            "[1 1 1 1 3 3 3 4 3 1 3 1 3 3 0 1]\n",
            "[1 1 1 1 3 3 3 3 3 1 3 1 3 3 0 1]\n",
            "[3 0 4 3 2 2 0 0 3 0 2 3 1 4 0 4]\n",
            "[3 0 4 3 2 2 0 0 3 0 2 3 1 4 0 4]\n",
            "[0 2 0 1 4 3 3 2 3 3 1 4 4 0 1 3]\n",
            "[0 2 0 1 4 3 3 2 3 3 1 4 4 0 1 3]\n",
            "[0 4 0 0 3 3 2 0 0 0 3 3 4 1 0 0]\n",
            "[0 4 0 0 3 3 2 0 0 0 3 3 4 3 0 0]\n",
            "[1 3 1 3 3 3 1 3 3 1 1 3 0 1 4 2]\n",
            "[1 3 1 3 1 3 1 3 3 1 1 3 0 1 3 2]\n",
            "[2 0 1 1 0 3 3 1 4 4 3 4 2 3 3 3]\n",
            "[2 0 1 1 0 3 3 1 4 4 3 4 2 3 3 3]\n",
            "[4 4 2 2 4 2 0 3 0 0 0 3 3 3 3 3]\n",
            "[4 4 2 2 4 2 0 4 0 0 0 3 3 3 3 2]\n",
            "[3 4 1 0 2 1 2 0 1 1 1 0 1 3 3 3]\n",
            "[3 4 1 0 2 1 4 0 1 1 1 0 1 3 3 3]\n",
            "[1 0 3 4 3 3 3 0 2 1 1 3 4 3 1 3]\n",
            "[1 0 3 3 3 3 3 0 2 1 1 3 4 3 1 3]\n",
            "[4 3 1 0 0 0 2 4 3 3 3 3 1 4 4 3]\n",
            "[3 3 1 0 0 0 2 4 3 3 3 3 1 3 4 3]\n",
            "[0 3 4 3 2 0 1 4 4 1 2 2 0 2 4 0]\n",
            "[0 3 4 3 2 0 1 4 4 1 2 2 0 2 4 0]\n",
            "[0 3 4 4 2 0 0 2 2 3 3 3 0 1 3 3]\n",
            "[0 4 4 4 2 0 0 2 2 3 3 3 0 1 3 3]\n",
            "[3 4 1 0 1 0 3 0 1 1 3 3 2]\n",
            "[3 2 1 0 1 0 3 0 1 1 3 3 2]\n",
            "Test Loss: 0.202595\n",
            "\n",
            "\n",
            "Test Accuracy: 94% (208/221)\n",
            "tensor([[48.,  0.,  0.,  0.,  0.],\n",
            "        [ 0., 41.,  0.,  1.,  0.],\n",
            "        [ 0.,  0., 24.,  0.,  1.],\n",
            "        [ 1.,  1.,  1., 69.,  2.],\n",
            "        [ 0.,  0.,  1.,  5., 26.]])\n",
            "                           precision    recall  f1-score   support\n",
            "\n",
            "               martensite       0.98      1.00      0.99        48\n",
            "                  network       0.98      0.98      0.98        42\n",
            "                 pearlite       0.92      0.96      0.94        25\n",
            "              spheroidite       0.92      0.93      0.93        74\n",
            "spheroidite_widmanstatten       0.90      0.81      0.85        32\n",
            "\n",
            "                 accuracy                           0.94       221\n",
            "                macro avg       0.94      0.94      0.94       221\n",
            "             weighted avg       0.94      0.94      0.94       221\n",
            "\n",
            "actual label [0, 3, 4, 0, 3, 4, 1, 3, 3, 0, 1, 2, 3, 0, 3, 0, 1, 1, 1, 1, 3, 3, 3, 4, 3, 1, 3, 1, 3, 3, 0, 1, 3, 0, 4, 3, 2, 2, 0, 0, 3, 0, 2, 3, 1, 4, 0, 4, 0, 2, 0, 1, 4, 3, 3, 2, 3, 3, 1, 4, 4, 0, 1, 3, 0, 4, 0, 0, 3, 3, 2, 0, 0, 0, 3, 3, 4, 1, 0, 0, 1, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 0, 1, 4, 2, 2, 0, 1, 1, 0, 3, 3, 1, 4, 4, 3, 4, 2, 3, 3, 3, 4, 4, 2, 2, 4, 2, 0, 3, 0, 0, 0, 3, 3, 3, 3, 3, 3, 4, 1, 0, 2, 1, 2, 0, 1, 1, 1, 0, 1, 3, 3, 3, 1, 0, 3, 4, 3, 3, 3, 0, 2, 1, 1, 3, 4, 3, 1, 3, 4, 3, 1, 0, 0, 0, 2, 4, 3, 3, 3, 3, 1, 4, 4, 3, 0, 3, 4, 3, 2, 0, 1, 4, 4, 1, 2, 2, 0, 2, 4, 0, 0, 3, 4, 4, 2, 0, 0, 2, 2, 3, 3, 3, 0, 1, 3, 3, 3, 4, 1, 0, 1, 0, 3, 0, 1, 1, 3, 3, 2]\n",
            "predicted label [0, 3, 4, 0, 3, 4, 1, 3, 3, 0, 1, 2, 3, 0, 0, 0, 1, 1, 1, 1, 3, 3, 3, 3, 3, 1, 3, 1, 3, 3, 0, 1, 3, 0, 4, 3, 2, 2, 0, 0, 3, 0, 2, 3, 1, 4, 0, 4, 0, 2, 0, 1, 4, 3, 3, 2, 3, 3, 1, 4, 4, 0, 1, 3, 0, 4, 0, 0, 3, 3, 2, 0, 0, 0, 3, 3, 4, 3, 0, 0, 1, 3, 1, 3, 1, 3, 1, 3, 3, 1, 1, 3, 0, 1, 3, 2, 2, 0, 1, 1, 0, 3, 3, 1, 4, 4, 3, 4, 2, 3, 3, 3, 4, 4, 2, 2, 4, 2, 0, 4, 0, 0, 0, 3, 3, 3, 3, 2, 3, 4, 1, 0, 2, 1, 4, 0, 1, 1, 1, 0, 1, 3, 3, 3, 1, 0, 3, 3, 3, 3, 3, 0, 2, 1, 1, 3, 4, 3, 1, 3, 3, 3, 1, 0, 0, 0, 2, 4, 3, 3, 3, 3, 1, 3, 4, 3, 0, 3, 4, 3, 2, 0, 1, 4, 4, 1, 2, 2, 0, 2, 4, 0, 0, 4, 4, 4, 2, 0, 0, 2, 2, 3, 3, 3, 0, 1, 3, 3, 3, 2, 1, 0, 1, 0, 3, 0, 1, 1, 3, 3, 2]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD4CAYAAACt8i4nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAa2klEQVR4nO3dfXRV9Z3v8fc3j4SQkPCQEEABEahYBSlNbZEOxdpRiqh3XNViHdprL65Va7VaW6dz7+3YdlrnzgzaWXfaIZVaZsQHrtZCaa/3ugS11QqiIvIMBa1EIDwEQiAEkvO9f+RAU26Sk+ScH5uz+bzWOitnP/3297e2fPydffY+29wdEREJJyfqAkRE4k5BKyISmIJWRCQwBa2ISGAKWhGRwPKC72HLxNhd1nD7nm9GXYJILM2fOtvSbWPZsmXdzpyZM2emvb/u0IhWRCQwBa2ISGAKWhGRwBS0IiKBKWhFRAJT0IqIBKagFREJTEErIhKYglZEJDAFrYhIYApaEZHAFLQiIoEpaEVEAlPQiogEpqAVEQlMQSsiEpiCVkQksPBPWAiotdX5q3uaqRxgzP9OIb9/u5X/8bMTJBz69jEevDufEUOz9/8l+9dtY9sTz+GJBFVTJzFixhVRl5QRcexXHPsE8e3XmZa9KQT8+69aGD38T134ux+f4J++UcCSf+nDzL/I5SdPtURYXXo8kWDrot9w6d23UP29O6hbtY4jH+yNuqy0xbFfcewTxLdfUcjaoN29z3nx9QQ3fib3TzMNGo+2vW086lQMPCOPAwqiYUctRRUDKBpcTk5eLhXVF7Nvzaaoy0pbHPsVxz5BfPsVhZSnDszsQ8B1wLDkrFpgqbtvDFlYKj/46XHu+1I+R5r+9By2v78zn7kPNFNYAP36Gov/qTDCCtPTXH+YwvLSU9OF5aU0bK+NsKLMiGO/4tgniG+/otDliNbMvgU8CRiwKvky4Akzu7+L7eaa2WozW13z1P5M1gvAilWtDOhvfPjCPy//50taqPlOIS//vIj/9OlcfvjIiYzvW0Skp1KNaG8DLnb3P0ssM5sHrAce7Ggjd68BaoAgjxt/c2OC5ataefmNYzQfdxqPwtwHmtm+05kwri18Z1yRy5f/7nimd33GFJaX0FzfcGq6ub6BwvKSCCvKjDj2K459gvj2KwqpztEmgKEdzK9KLovEvXPyefnnRSxf0Id53yzg8ktz+PF/LeDwEWdHbVtZr6xJMHp49p6jLRk5jKY9+2naW0+ipZW6VesZNGFc1GWlLY79imOfIL79ikKqEe3dwAtmthV4PznvfOBC4KshC+upvFzj+3cW8LUfHscM+vczfnBXftRl9VpObg5jZs9g7cOP4QmnaspEiodVRF1W2uLYrzj2CeLbryiYe9ef7M0sB6jmz78Me93dW7u1hwCnDqJ2+55vRl2CSCzNnzo77Y+hy5Yt63bmzJw5s8v9mVkZ8AjwYcCB/wxsBp4CRgLvAp9z9/qu2kl51YG7J4DXulO0iEjM/Ah4zt1vNLMCoC/wbeAFd38weVHA/cC3umokq+8MExE53aTy9zLSjpn1Bz4JfBHA3Y8Dx83sOmBacrWFwIukCNqsvWFBRCRd7S9FTb7mtls8CtgLPGpmb5nZI2ZWDFS6+67kOruBylT70YhWRM5Zf3Yp6v8vD5gE3OnuK83sR7SdJmi/vZtZynPCGtGKiHRsJ7DT3Vcmp5+mLXj3mFkVQPJvXaqGFLQiIh1w993A+2Z28uLhK4ENwFJgTnLeHGBJqrZ06kBEpHN3AouSVxxsB75E2wB1sZndBrwHfC5VIwpaEZFOuPsaYHIHi67sSTs6dSAiEpiCVkQkMAWtiEhgCloRkcAUtCIigSloRUQCU9CKiASmoBURCSz4DQtx/JHsaRXPRl1CEC/W3RB1CSKxpBGtiEhgCloRkcAUtCIigSloRUQCU9CKiASmoBURCUxBKyISmIJWRCQwBa2ISGAKWhGRwBS0IiKB6eGMIhIrQwf/tAdr3xGsjvY0ohURCUwjWhGRTpjZu8BhoBVocffJZjYAeAoYCbwLfM7d67tqRyNaEZGufcrdJ7r75OT0/cAL7j4GeCE53SUFrYhIz1wHLEy+Xwhcn2oDBa2InLPMbK6ZrW73mnvaKg78XzN7o92ySnfflXy/G6hMtZ9YnKPdv24b2554Dk8kqJo6iREzroi6pLQkWp2ae7ZSMjCfW/77KFYu28drS/dRv/s49z02nuLS7D5scTteAJseXcL+tVvILymm+rtfibqcjInjsWrP3WuAmi5WucLda82sAnjezDadtr2bmafaT9aPaD2RYOui33Dp3bdQ/b07qFu1jiMf7I26rLS89qt9DDqvz6np8y8q5q+/dwH9K/IjrCoz4ni8AIZMmcild38h6jIyKq7HqifcvTb5tw54FqgG9phZFUDyb12qdrI+aBt21FJUMYCiweXk5OVSUX0x+9ZsSr3hWerQvuNsXX2YSVcNODWvanQR5ZUFEVaVOXE7XieVjR1BXnFR1GVkVFyPVXeZWbGZlZx8D3wGWAcsBeYkV5sDLEnVVtYHbXP9YQrLS09NF5aX0lx/OMKK0vPcI7u46otDsKw/Mh2L2/GKMx0rKoHfmdnbwCrg1+7+HPAgcJWZbQU+nZzuUnaf7IuZza83UNw/j6EX9mXHO41RlyNyTnP37cCEDubvB67sSVu9HjeZ2Ze6WHbqm7yNS5f3dhfdUlheQnN9w6np5voGCstLgu4zlPc3HGHzqgYe+vJGnv7HP7JjbSPP/PMfoy4ro+J0vOJOxypz0vmA+kBnC9y9xt0nu/vki2ZNT2MXqZWMHEbTnv007a0n0dJK3ar1DJowLug+Q/n0nCruffQivv7IRdx43/mMurQff3Xv+VGXlVFxOl5xp2OVOV2eOjCztZ0tohvXjp0JObk5jJk9g7UPP4YnnKopEykeVhF1WRn12q/28cov9tJYf4KffG0LYz5SwnV3nhd1Wb0S1+O1oeYZDm5+lxONR3n1vnmMmjWNqqmToi4rLXE9VlEw984vATOzPcBfAqffx2vAq+4+NNUObv/t4ymvMcs20yqejbqEIF6suyHqEuQcN3/qbEu7kS0Tu585Y9ekv79uSPVl2DKgn7uvOX2Bmb0YpCIRkZjpMmjd/bYuls3OfDkiIvET06s1RUTOHgpaEZHAFLQiIoEpaEVEAlPQiogEpqAVEQlMQSsiEpiCVkQkMAWtiEhgCloRkcD0w98iEitP+Jhur/v5gHW0pxGtiEhgCloRkcAUtCIigSloRUQC05dhvRDXJxGM2z426hIybvMFW6IuQUQjWhGR0BS0IiJdMLNcM3vLzJYlp0eZ2Uoz22ZmT5lZQao2FLQiIl27C9jYbvofgIfc/ULaHlzb6SO/TlLQioh0wsyGA58FHklOGzAdeDq5ykLg+lTtKGhF5JxlZnPNbHW719zTVnkY+CaQSE4PBA66e0tyeicwLNV+dNWBiJyz3L0GqOlomZnNBOrc/Q0zm5bOfhS0IiIdmwLMMrMZQB+gFPgRUGZmeclR7XCgNlVDOnUgItIBd/8bdx/u7iOBm4Hl7n4LsAK4MbnaHGBJqrYUtCIiPfMt4B4z20bbOdsFqTbQqQMRkRTc/UXgxeT77UB1T7bXiFZEJDAFrYhIYApaEZHAFLQiIoEpaEVEAlPQiogEpqAVEQksFtfR7l+3jW1PPIcnElRNncSIGVdEXVJGxKVf/frmc80Vo+hblI8D72zZy1sb604t/8j4Sv7io+fx4yfXcKy5pfOGzmJxOVbtbXp0CfvXbiG/pJjq734l6nKyWtYHrScSbF30GybccyuF5aW88f2fMmjiOIqHDo66tLTEqV/u8NLqndQdOEp+Xg5fmDme9z5o4MChY/Trm8+IoaU0NDZHXWavxelYtTdkykSGTa9m44Jnoy4l62X9qYOGHbUUVQygaHA5OXm5VFRfzL41m6IuK21x6teRphPUHTgKwImWBPsPNdGvb9uP0k/76Hm8/MZOPMoC0xSnY9Ve2dgR5BUXRV1GLKQMWjP7kJldaWb9Tpt/dbiyuq+5/jCF5aWnpgvLS2muPxxhRZkR136VFhdQMaAvu/c1Mvq8MhqPnmBffVPUZaUlrsdKMqfLoDWzr9H2yzR3AuvM7Lp2i3/QxXanfkx349LlmalUsl5+Xg7Xfmo0L77+PokEVF8yhFfXfBB1WSLBpTpH+1+Aj7h7o5mNBJ42s5Hu/iPAOtuo/Y/p3v7bx4N+KiwsL6G5vuHUdHN9A4XlJSF3eUbErV85Zlw7bTQbtx9g2x8PMqisiP79Crl11ngASvoW8IWZF/H4rzdy9Fh2fSEWt2OV7T619K7ur3xfuDraS3XqIMfdGwHc/V1gGnCNmc2ji6A9k0pGDqNpz36a9taTaGmlbtV6Bk0YF3VZaYtbvz4zZQQHDh3jzQ17ANh3sIl/W/w2C555hwXPvMPho8d5bFn2hSzE71hJ5qUa0e4xs4nuvgYgObKdCfwMuCR4dd2Qk5vDmNkzWPvwY3jCqZoykeJhFVGXlbY49WtoRT/Gjx7E3gNH+cK1bSPYV96sZUftoYgry4w4Hav2NtQ8w8HN73Ki8Siv3jePUbOmUTV1UtRlZSVz7/yTffIJkC3uvruDZVPc/ZVUOwh96kAyZ9z2sVGXkHGbL9gSdQnSA/Onzk77k/Luf/xdtzNnyH1XnJFP5l2OaN19ZxfLUoasiIjE4DpaEZGznYJWRCQwBa2ISGAKWhGRwBS0IiKBKWhFRDpgZn3MbJWZvW1m683sgeT8UWa20sy2mdlTZlaQqi0FrYhIx5qB6e4+AZgIXG1mlwP/ADzk7hcC9cBtqRpS0IqIdMDbNCYn85MvB6YDTyfnLwSuT9WWglZEzlntf2kw+Zp72vJcM1sD1AHPA38ADrr7yR/l2AkMS7WfrH/CgohIb7X/pcFOlrcCE82sDHgW+FBv9qMRrYhICu5+EFgBfBwoM7OTg9ThQG2q7RW0IiIdMLPByZEsZlYEXAVspC1wb0yuNoe2hyN0SacOREQ6VgUsNLNc2gali919mZltAJ40s+8DbwELUjWkoBUR6YC7rwUu62D+dqC6J23p1IGISGAa0copcfyR7GsPlaZeKQv9qn9D6pXkrKERrYhIYApaEZHAFLQiIoEpaEVEAlPQiogEpqAVEQlMl3eJSKw8XtGn2+veE7CO9jSiFREJTEErIhKYglZEJDAFrYhIYApaEZHAFLQiIoEpaEVEAlPQiogEpqAVEQlMQSsiElgsbsHd9OgS9q/dQn5JMdXf/UrU5WREHPsE8epXU1MTixcvZteuXZgZN910EwUFBTz99NM0NzczYMAAbrnlFvr06f4toWeTYwcOsWnBLzne0AhmDP3kJIZ/+vKoy8pKsQjaIVMmMmx6NRsXPBt1KRkTxz5BvPr1y1/+knHjxjFnzhxaWlo4ceIE8+fP59prr2X06NGsXLmSFStWcM0110Rdaq9YTg6jP/cZSkZU0XKsmTe+V0P5+NEUDx0cdWlZJxanDsrGjiCvuCjqMjIqjn2C+PSrqamJ7du387GPfQyAvLw8ioqK2Lt3LxdccAEAY8eO5Z133omyzLQUlpVQMqIKgLw+hfStGkxzvZ5V1huxGNGKnGkHDhyguLiYJ598kg8++IDhw4dz/fXXU1lZybp167jkkktYu3YtBw8ejLrUjGjad5DGP+6i9ILhUZeSlVKOaM2s2sw+mnw/3szuMbMZ4UsTOXslEglqa2v5xCc+wb333kthYSHLly/npptu4tVXX+Whhx7i2LFj5ObmRl1q2lqOHWf9jxdz4U1Xk1dUGHU5Z4yZnWdmK8xsg5mtN7O7kvMHmNnzZrY1+bc8VVtdBq2ZfQf4F+AnZvZD4H8CxcD9Zva3XWw318xWm9nqjUuX96hzItmgf//+9O/fnxEjRgBw6aWXUltbS2VlJbfffjtf//rXmTRpEgMHDoy40vQkWlpZ/5PFVF5+CYM/clHU5ZxpLcC97j4euBy4w8zGA/cDL7j7GOCF5HSXUo1obwSmAJ8E7gCud/fvAX8J3NTZRu5e4+6T3X3yRbOmd6dDIlmltLSUsrIy6urqANi6dSuVlZUcPnwYaBvxPv/883z84x+Pssy0uDubFy6lb9UgzvtM9vajt9x9l7u/mXx/GNgIDAOuAxYmV1sIXJ+qrVTnaFvcvRU4amZ/cPeG5E6bzCzR2w5k2oaaZzi4+V1ONB7l1fvmMWrWNKqmToq6rLTEsU8Qr37dcMMNLFq0iNbWVgYMGMDNN9/M6tWreeWVVwC45JJLqK6ujrjK3ju07X32/H4txcMqeP2BfwPgghuuZOClYyKuLHPMbC4wt92sGnev6WC9kcBlwEqg0t13JRftBipT7sfduypiJfApdz9qZjnunkjO7w+scPeU/0Ju/+3jne9AJLBrD5VGXUIQv+ofz2//50+dbem2MW/h6m5nzj1zJqfcn5n1A14C/t7df2FmB929rN3yenfv8jxtqlMHn3T3owAnQzYpH5iTqkARkWxmZvnAM8Aid/9FcvYeM6tKLq8C6lK102XQuntzJ/P3uXv2XiAoIpKCmRmwANjo7vPaLVrKnwaac4AlqdrSdbQiIh2bAtwKvGNma5Lzvg08CCw2s9uA94DPpWpIQSsi0gF3/x3Q2TncK3vSVixuwRUROZspaEVEAlPQiogEpnO0IhIrd+3/SQ/WXhCsjvY0ohURCUxBKyISmIJWRCQwBa2ISGAKWhGRwBS0IiKBKWhFRAJT0IqIBKagFREJTHeGSazF9UkED7x2ftQlhDE16gLC0IhWRCQwBa2ISGAKWhGRwBS0IiKBKWhFRAJT0IqIBKagFREJTEErIhKYglZEpBNm9jMzqzOzde3mDTCz581sa/Jveap2FLQiIp37OXD1afPuB15w9zHAC8npLiloRUQ64e4vAwdOm30dsDD5fiFwfap2FLQics4ys7lmtrrda243Nqt0913J97uBylQb6EdlROSc5e41QE0a27uZear1NKIVEemZPWZWBZD8W5dqAwWtiEjPLAXmJN/PAZak2kBBKyLSCTN7Avg9MM7MdprZbcCDwFVmthX4dHK6SzpHKyKx8pWPXtntdeenWO7un+9kUfd3QkyCdv+6bWx74jk8kaBq6iRGzLgi6pIyIo792vToEvav3UJ+STHV3/1K1OVkzO+/9TB5fQohx7CcHCb/t+58eX32ySkpoP+MseT2LcBxmt7ew9E3PwCg72VV9L2sCneneXs9jS+9G22xWSTrg9YTCbYu+g0T7rmVwvJS3vj+Txk0cRzFQwdHXVpa4tqvIVMmMmx6NRsXPBt1KRk34RtzKCjpG3UZ6Uk4h1fsoKXuCJafy8C/nkjze/Xk9i2gcMxA9i18C1qdnL75UVeaVbL+HG3DjlqKKgZQNLicnLxcKqovZt+aTVGXlba49qts7AjyiouiLkM6kThygpa6IwD4iVZa9h8lt18hRROHcGTl+9DadiVT4uiJKMvMOj0OWjP79xCF9FZz/WEKy0tPTReWl9JcfzjCijIjrv2KKzNj7UP/werv1vDBS29EXU5G5JYWkl9ZzIldh8kbUETB8P4MuGUCA26+hLwh/aIuL6t0eerAzJaePgv4lJmVAbj7rE62mwvMBZj6jdu4aNb0DJQqcva67FtforC8lOMNR3h73n/Qt2oQZWNHRF1Wr1l+DmXXXUTD8h348VYww/rkcWDR2+QP6UfZtR9i309XR11m1kh1jnY4sAF4BHDagnYy8M9dbdT+bovbf/t4yrsm0lFYXkJz/Z8eKd1c30BheUnIXZ4Rce1XXJ389FFQWsygyz5Ew47a7A3aHKPsuoto2lhH89b9ACQaj9O8pe39id2NgGNFeXhTS4SFZo9Upw4mA28AfwsccvcXgSZ3f8ndXwpdXHeUjBxG0579NO2tJ9HSSt2q9QyaMC7qstIW137FUWvzcVqONZ96X7/hDxQPq4i4qt7rf/UYWvYf5ejqD07NO7Z1PwXn9wcgt7wPlpOjkO2BLke07p4AHjKz/5X8uyfVNmdaTm4OY2bPYO3Dj+EJp2rKxKz+j/ykuPZrQ80zHNz8Licaj/LqffMYNWsaVVMnRV1WWo43HGHdvz4FtF0tUln9YQZ++MKIq+qd/GGlFF1cwYm9Rxg4ZyIAh19+j6Z39tD/mjEM/OJlkHAO/e8tEVeaXcy9+5/szeyzwBR3/3Z3twl96kDkXPTAa+dHXUIQQ+67wtJtoyeZM3/q7LT31x09Gp26+6+BXweqRUQklrL+OloRkbOdglZEJDAFrYhIYApaEZHAFLQiIoEpaEVEAlPQiogEpqAVEQlMQSsiEpiCVkQkMAWtiEhgCloRkcAUtCIigSloRUQ6YWZXm9lmM9tmZvf3th0FrYhIB8wsF/hX4BpgPPB5Mxvfm7YUtCIiHasGtrn7dnc/DjwJXNebhnr0hIWznZnNTT4YMlbi2K849gni2a849umk9k/sTqo52VczuxG42t2/nJy+FfiYu3+1p/uJ24h2bupVslIc+xXHPkE8+xXHPgFtT+x298ntXkH+hxK3oBURyZRa4Lx208OT83pMQSsi0rHXgTFmNsrMCoCbgaW9aeisenR4BsTyPBLx7Fcc+wTx7Fcc+5SSu7eY2VeB/wPkAj9z9/W9aStWX4aJiJyNdOpARCQwBa2ISGCxCNpM3SZ3NjGzn5lZnZmti7qWTDKz88xshZltMLP1ZnZX1DWly8z6mNkqM3s72acHoq4pk8ws18zeMrNlUdeSrbI+aDN5m9xZ5ufA1VEXEUALcK+7jwcuB+6IwfFqBqa7+wRgInC1mV0ecU2ZdBewMeoislnWBy0ZvE3ubOLuLwMHoq4j09x9l7u/mXx/mLZ/wMOirSo93qYxOZmffMXiW2YzGw58Fngk6lqyWRyCdhjwfrvpnWT5P9xzhZmNBC4DVkZbSfqSH6/XAHXA8+6e9X1Kehj4JpCIupBsFoeglSxkZv2AZ4C73b0h6nrS5e6t7j6RtruHqs3sw1HXlC4zmwnUufsbUdeS7eIQtBm7TU7ODDPLpy1kF7n7L6KuJ5Pc/SCwgnicX58CzDKzd2k7JTfdzB6LtqTsFIegzdhtchKemRmwANjo7vOiricTzGywmZUl3xcBVwGboq0qfe7+N+4+3N1H0vbvarm7fyHisrJS1getu7cAJ2+T2wgs7u1tcmcTM3sC+D0wzsx2mtltUdeUIVOAW2kbHa1JvmZEXVSaqoAVZraWtv/xP+/uuhRKTtEtuCIigWX9iFZE5GynoBURCUxBKyISmIJWRCQwBa2ISGAKWhGRwBS0IiKB/T/fq4UgQJYp3gAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OtShw5JdiNPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train_loss=\",train_loss_list)\n",
        "print(\"valid_loss=\",valid_loss_list)\n",
        "print(\"Train_accuracy=\",train_accuracy_list)\n",
        "print(\"valid_accuracy=\",valid_accuracy_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kySLjct8iOpV",
        "outputId": "5b5ccc46-aed3-48c5-bfe1-0af861379782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train_loss= [1.4720533652739092, 1.201001457192681, 1.0137922289696606, 0.8632253367792476, 0.77098244225437, 0.6865420178933577, 0.6292502290823243, 0.5817894332788207, 0.5606180256740614, 0.5210456116632982, 0.5330244461921129, 0.5069763264195486, 0.4892185459082777, 0.4859359179708091, 0.44665334204381163, 0.4106007218360901, 0.38552097739143804, 0.4141560379754413, 0.44688932021910494, 0.3749174956570972, 0.4110323945907029, 0.37217986380512064, 0.35795746879144147, 0.3795559663664211, 0.34150683388791303, 0.3497225989333608, 0.3231010692702098, 0.344028229740533, 0.31094396469945257, 0.33174698715182865, 0.3112253407863053, 0.3015671413053166, 0.3185844189402732, 0.29851569252258, 0.28960855677723885, 0.30239400758662005, 0.2989572042768652, 0.28304182746532286, 0.297441804273562, 0.2698342175307599, 0.329226996072314, 0.2618118462745439, 0.2533590200949799, 0.293833926320076, 0.24474303500557487, 0.2707521185617555, 0.2808034369214015, 0.2679309296337041, 0.2898673453706909, 0.279218479482965]\n",
            "valid_loss= [6.557749802416021, 5.076663846319372, 4.0711310072378675, 3.406502417542718, 2.945156690749255, 2.6661693264137614, 2.5077300017530266, 2.194652026349848, 2.0678825920278374, 1.9653409909118305, 1.8459903543645686, 1.7010869275439868, 1.701004595919089, 1.6804112873294137, 1.5740869329734282, 1.5515270057049664, 1.4497423551299355, 1.3387815207242966, 1.321985456415198, 1.350313819267533, 1.3056481609290296, 1.2683671103282408, 1.2928085719997233, 1.2583734487945384, 1.1997741040858356, 1.1596940430727871, 1.1152277155355974, 1.1202803071249614, 1.0114245861768723, 1.0107430219650269, 1.0503338761627674, 0.9836747029965575, 0.9633065804161809, 1.058452276682312, 0.9588660756972703, 0.9868455810303037, 0.9425947517156601, 0.9186535989019003, 0.9584739265794103, 0.8965079310265455, 0.9516981183127924, 0.864617757499218, 0.8468849862163718, 0.8665075027807192, 0.8501890484582294, 0.8129970654845238, 0.8628632812337442, 0.8710718607022003, 0.8217288851737976, 0.820862260393121]\n",
            "Train_accuracy= [0.5295712812380358, 0.737345041199164, 0.8104338849132712, 0.826188017021526, 0.8424586775628004, 0.8602789261124351, 0.8680268593809821, 0.8716425624760714, 0.8666064048355276, 0.8863636363636364, 0.8879132230173458, 0.8999225212769075, 0.9048295454545454, 0.8956611576405439, 0.9056043394587256, 0.901342975822362, 0.9226497940041802, 0.9318181818181818, 0.9275568181818182, 0.9303977272727273, 0.9270402897487987, 0.9213584715669806, 0.9161931818181818, 0.9163223139264367, 0.9347882230173458, 0.9297520667314529, 0.9333677684718912, 0.9354338849132712, 0.9375, 0.9396952485496347, 0.9347882230173458, 0.948217975822362, 0.9588068181818182, 0.9256198352033441, 0.9396952485496347, 0.9332386363636364, 0.9411157030950893, 0.9439566121859984, 0.9403409090909091, 0.9474431818181818, 0.9446022727272727, 0.9488636363636364, 0.9504132230173458, 0.9446022727272727, 0.9588068181818182, 0.9575154957446185, 0.9460227272727273, 0.9538997940041802, 0.9517045454545454, 0.9588068181818182]\n",
            "valid_accuracy= [0.5568181818181818, 0.7370129877870734, 0.8262987028468739, 0.8441558426076715, 0.8449675332416188, 0.8400974002751437, 0.8612012971531261, 0.8831168846650557, 0.8863636363636364, 0.8847402605143461, 0.8977272727272727, 0.8733766241507097, 0.9131493514234369, 0.8904220786961642, 0.8725649335167625, 0.9090909090909091, 0.879870127547871, 0.9147727272727273, 0.8855519457296892, 0.8912337639115073, 0.9025974002751437, 0.9366883093660529, 0.9074675332416188, 0.8863636363636364, 0.91396103663878, 0.9034090909090909, 0.9147727272727273, 0.9204545454545454, 0.9196428548205983, 0.9066558426076715, 0.9196428548205983, 0.9082792184569619, 0.9025974002751437, 0.9318181818181818, 0.9082792184569619, 0.9131493514234369, 0.9188311696052551, 0.9017857150598005, 0.9058441573923285, 0.9253246730024164, 0.9074675332416188, 0.9310064911842346, 0.9253246730024164, 0.9147727272727273, 0.91396103663878, 0.9545454545454546, 0.9017857150598005, 0.9131493514234369, 0.9204545454545454, 0.918019478971308]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LqxEztOWiPr1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}